{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "GRID_HEIGHT = 5\n",
    "GRID_WIDTH = 5\n",
    "A_POSITION = (0, 1)  # Position of special state A\n",
    "A_PRIME_POSITION = (4, 1)  # Destination of state A with reward +10\n",
    "B_POSITION = (0, 3)  # Position of special state B\n",
    "B_PRIME_POSITION = (2, 3)  # Destination of state B with reward +5\n",
    "GAMMA = 0.9  # Discount factor\n",
    "THETA = 1e-4  # Convergence threshold for Value Iteration\n",
    "ACTIONS = ['U', 'D', 'L', 'R']  # Available actions: Up, Down, Left, Right\n",
    "ACTION_DELTA = {\n",
    "    'U': (-1, 0),  # Move up\n",
    "    'D': (1, 0),   # Move down\n",
    "    'L': (0, -1),  # Move left\n",
    "    'R': (0, 1),   # Move right\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_state(state):\n",
    "    \"\"\"\n",
    "    Check if the state is within grid boundaries.\n",
    "\n",
    "    Args:\n",
    "        state (tuple): The state to check (i, j).\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the state is valid, False otherwise.\n",
    "    \"\"\"\n",
    "    i, j = state\n",
    "    return 0 <= i < GRID_HEIGHT and 0 <= j < GRID_WIDTH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_state_and_reward(state, action):\n",
    "    \"\"\"\n",
    "    Given a state and an action, return the next state and reward.\n",
    "\n",
    "    Args:\n",
    "        state (tuple): The current state (i, j).\n",
    "        action (str): The action taken ('U', 'D', 'L', 'R').\n",
    "\n",
    "    Returns:\n",
    "        next_state (tuple): The next state after taking the action.\n",
    "        reward (float): The reward received after taking the action.\n",
    "    \"\"\"\n",
    "    if state == A_POSITION:\n",
    "        # Special transition for state A with reward +10\n",
    "        return A_PRIME_POSITION, 10.0\n",
    "    if state == B_POSITION:\n",
    "        # Special transition for state B with reward +5\n",
    "        return B_PRIME_POSITION, 5.0\n",
    "\n",
    "    delta = ACTION_DELTA[action]\n",
    "    next_state = (state[0] + delta[0], state[1] + delta[1])\n",
    "\n",
    "    if not is_valid_state(next_state):\n",
    "        # If next state is off the grid, stay in the same state and penalize\n",
    "        return state, -1.0\n",
    "\n",
    "    return next_state, 0.0  # Reward is 0 for all standard transitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration():\n",
    "    \"\"\"\n",
    "    Perform Value Iteration to compute the optimal state-value function.\n",
    "\n",
    "    Returns:\n",
    "        V (numpy.ndarray): The optimal state-value function as a 2D numpy array.\n",
    "    \"\"\"\n",
    "    V = np.zeros((GRID_HEIGHT, GRID_WIDTH))\n",
    "    while True:\n",
    "        delta = 0  # Initialize delta for convergence checking\n",
    "        for i in range(GRID_HEIGHT):\n",
    "            for j in range(GRID_WIDTH):\n",
    "                state = (i, j)\n",
    "                v = V[state]\n",
    "                values = []\n",
    "                # Evaluate all possible actions\n",
    "                for action in ACTIONS:\n",
    "                    next_state, reward = get_next_state_and_reward(state, action)\n",
    "                    value = reward + GAMMA * V[next_state]\n",
    "                    values.append(value)\n",
    "                V[state] = max(values)  # Update the state-value with the maximum action value\n",
    "                delta = max(delta, abs(v - V[state]))\n",
    "        if delta < THETA:\n",
    "            # Value function has converged\n",
    "            break\n",
    "    return V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  v_*\n",
      "       Col 0  Col 1  Col 2  Col 3  Col 4\n",
      "Row 0    22.0   24.4   22.0   19.4   17.5\n",
      "Row 1    19.8   22.0   19.8   17.8   16.0\n",
      "Row 2    17.8   19.8   17.8   16.0   14.4\n",
      "Row 3    16.0   17.8   16.0   14.4   13.0\n",
      "Row 4    14.4   16.0   14.4   13.0   11.7\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to compute and display the optimal state-value function.\n",
    "    \"\"\"\n",
    "    V = value_iteration()\n",
    "    # Print the formatted optimal state-value function\n",
    "    print(\"                  v_*\")\n",
    "    print(\"       \" + \"  \".join([f\"Col {j}\" for j in range(GRID_WIDTH)]))\n",
    "    for i in range(GRID_HEIGHT):\n",
    "        print(f\"Row {i} \", end='')\n",
    "        for j in range(GRID_WIDTH):\n",
    "            print(f\"{V[i, j]:7.1f}\", end='')\n",
    "        print()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
